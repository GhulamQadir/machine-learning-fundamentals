{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9818edf9",
   "metadata": {},
   "source": [
    "# **Regularization**\n",
    "- Regularization is a technique in machine learning used to prevent overfitting by adding a penalty to large coefficients.\n",
    "\n",
    "- In simple words → it makes the model simpler by shrinking the weights (slopes).\n",
    "\n",
    "- Think of it as: \"Don’t let the line tilt too aggressively, keep coefficients small and stable.\"\n",
    "\n",
    "There are mainly two types:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac74022",
   "metadata": {},
   "source": [
    "## 1. **Ridge Regression (L2 Regularization)**\n",
    "- Ridge Regression is a type of linear regression that adds a penalty to large coefficients to prevent overfitting. \n",
    "- It shrinks coefficients (slopes) but never makes them exactly zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f61edcbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nRidge Regression (L2 Regularization)\\n------------------------------------\\n\\nMathematical Model:\\n    ŷ = B0 + B1*x\\n\\nHow Ridge differs from Linear Regression:\\n    In normal Linear Regression:\\n        B1 = Σ(xi - x̄)(yi - ȳ) / Σ(xi - x̄)²\\n\\n    In Ridge Regression:\\n        B1 = Σ(xi - x̄)(yi - ȳ) / [Σ(xi - x̄)² + λ]\\n\\n    - λ (lambda) is the regularization strength (hyperparameter).\\n    - Larger λ → coefficients shrink more (slope becomes smaller).\\n    - λ = 0 → Ridge becomes normal linear regression.\\n    \\nIntercept (B0):\\n    Still calculated the same way:\\n        B0 = ȳ - B1 * x̄\\n    But because B1 is smaller in Ridge, B0 adjusts accordingly.\\n    \\nExample:\\n    x = [1,2,3,4,5], y = [3,4,2,5,6]\\n    x̄ = 3, ȳ = 4\\n\\n    Numerator = 7\\n    Denominator = 10 + λ\\n\\n    If λ = 2:\\n        B1 = 7 / 12 = 0.583\\n        B0 = 4 - (0.583 * 3) = 2.251\\n\\n    Final Ridge line:\\n        ŷ = 2.251 + 0.583x\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Ridge Regression (L2 Regularization)\n",
    "------------------------------------\n",
    "\n",
    "Mathematical Model:\n",
    "    ŷ = B0 + B1*x\n",
    "\n",
    "How Ridge differs from Linear Regression:\n",
    "    In normal Linear Regression:\n",
    "        B1 = Σ(xi - x̄)(yi - ȳ) / Σ(xi - x̄)²\n",
    "\n",
    "    In Ridge Regression:\n",
    "        B1 = Σ(xi - x̄)(yi - ȳ) / [Σ(xi - x̄)² + λ]\n",
    "\n",
    "    - λ (lambda) is the regularization strength (hyperparameter).\n",
    "    - Larger λ → coefficients shrink more (slope becomes smaller).\n",
    "    - λ = 0 → Ridge becomes normal linear regression.\n",
    "    \n",
    "Intercept (B0):\n",
    "    Still calculated the same way:\n",
    "        B0 = ȳ - B1 * x̄\n",
    "    But because B1 is smaller in Ridge, B0 adjusts accordingly.\n",
    "    \n",
    "Example:\n",
    "    x = [1,2,3,4,5], y = [3,4,2,5,6]\n",
    "    x̄ = 3, ȳ = 4\n",
    "\n",
    "    Numerator = 7\n",
    "    Denominator = 10 + λ\n",
    "\n",
    "    If λ = 2:\n",
    "        B1 = 7 / 12 = 0.583\n",
    "        B0 = 4 - (0.583 * 3) = 2.251\n",
    "\n",
    "    Final Ridge line:\n",
    "        ŷ = 2.251 + 0.583x\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "caae167a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d81dcb47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>MedHouseVal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.3252</td>\n",
       "      <td>41.0</td>\n",
       "      <td>6.984127</td>\n",
       "      <td>1.023810</td>\n",
       "      <td>322.0</td>\n",
       "      <td>2.555556</td>\n",
       "      <td>37.88</td>\n",
       "      <td>-122.23</td>\n",
       "      <td>4.526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.3014</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6.238137</td>\n",
       "      <td>0.971880</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>2.109842</td>\n",
       "      <td>37.86</td>\n",
       "      <td>-122.22</td>\n",
       "      <td>3.585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.2574</td>\n",
       "      <td>52.0</td>\n",
       "      <td>8.288136</td>\n",
       "      <td>1.073446</td>\n",
       "      <td>496.0</td>\n",
       "      <td>2.802260</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.24</td>\n",
       "      <td>3.521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.6431</td>\n",
       "      <td>52.0</td>\n",
       "      <td>5.817352</td>\n",
       "      <td>1.073059</td>\n",
       "      <td>558.0</td>\n",
       "      <td>2.547945</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>3.413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.8462</td>\n",
       "      <td>52.0</td>\n",
       "      <td>6.281853</td>\n",
       "      <td>1.081081</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.181467</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>3.422</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
       "0  8.3252      41.0  6.984127   1.023810       322.0  2.555556     37.88   \n",
       "1  8.3014      21.0  6.238137   0.971880      2401.0  2.109842     37.86   \n",
       "2  7.2574      52.0  8.288136   1.073446       496.0  2.802260     37.85   \n",
       "3  5.6431      52.0  5.817352   1.073059       558.0  2.547945     37.85   \n",
       "4  3.8462      52.0  6.281853   1.081081       565.0  2.181467     37.85   \n",
       "\n",
       "   Longitude  MedHouseVal  \n",
       "0    -122.23        4.526  \n",
       "1    -122.22        3.585  \n",
       "2    -122.24        3.521  \n",
       "3    -122.25        3.413  \n",
       "4    -122.25        3.422  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing = fetch_california_housing(as_frame=True)\n",
    "\n",
    "# 'housing' is a Bunch object (like a dictionary with extra attributes)\n",
    "# housing.data   -> features (X)\n",
    "# housing.target -> target values (y)\n",
    "# housing.frame  -> full pandas DataFrame with both features + target combined\n",
    "df = housing.frame\n",
    "\n",
    "# Show first 5 rows of the dataset\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "91baab1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the input features (X) from the dataset\n",
    "# .drop(\"MedHouseVal\", axis=1) removes the target column (house value)\n",
    "# axis=1 → means drop by column (axis=0 would mean drop by row)\n",
    "# Result: 'x' contains only independent variables (features) like MedInc, HouseAge, etc.\n",
    "x = df.drop(\"MedHouseVal\", axis=1)\n",
    "\n",
    "# Select the target column (dependent variable)\n",
    "# 'y' will only contain the house prices (MedHouseVal) which we want to predict\n",
    "y = df[\"MedHouseVal\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "524603a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the input features (X) from the dataset\n",
    "# .drop(\"MedHouseVal\", axis=1) removes the target column (house value)\n",
    "# axis=1 → means drop by column (axis=0 would mean drop by row)\n",
    "# Result: 'x' contains only independent variables (features) like MedInc, HouseAge, etc.\n",
    "x = df.drop(\"MedHouseVal\", axis=1)\n",
    "\n",
    "# Select the target column (dependent variable)\n",
    "# 'y' will only contain the house prices (MedHouseVal) which we want to predict\n",
    "y = df[\"MedHouseVal\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "13f2bc04",
   "metadata": {},
   "outputs": [],
   "source": [
    "#   test_size=0.2 -> 20% data will go to testing, 80% to training\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=45\n",
    ")\n",
    "# random_state=45 → fixes the randomness of data splitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc318c6",
   "metadata": {},
   "source": [
    "### **Standard Scaler**\n",
    "- StandardScaler is a preprocessing technique in Machine Learning that ensures all features are on the same scale before training a model.\n",
    "- In raw datasets, some features may have very large values (e.g., income = 100,000) while others may have very small values (e.g., age = 20). This imbalance can cause the model to give more importance to larger-valued features just because of their scale, not because they are truly more important."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef5e6988",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nStandardScaler Example (Step by Step)\\n\\nWe want to standardize the data:\\n    X = [10, 20, 30, 40, 50]\\n\\nFormula:\\n    z_i = (x_i - μ) / σ\\n    where μ = mean, σ = standard deviation\\n\\n-----------------------------------------------------\\nStep 1: Compute mean (μ)\\n    μ = (10 + 20 + 30 + 40 + 50) / 5 = 30\\n\\nStep 2: Compute variance and std (σ)\\n    (10-30)² = 400\\n    (20-30)² = 100\\n    (30-30)² = 0\\n    (40-30)² = 100\\n    (50-30)² = 400\\n    Sum = 1000\\n\\n    Variance = 1000 / 5 = 200\\n    σ = √200 ≈ 14.142\\n\\nStep 3: Transform values (z = (x - μ) / σ)\\n    For 10 → (10-30)/14.142 ≈ -1.414\\n    For 20 → (20-30)/14.142 ≈ -0.707\\n    For 30 → (30-30)/14.142 = 0\\n    For 40 → (40-30)/14.142 ≈ 0.707\\n    For 50 → (50-30)/14.142 ≈ 1.414\\n\\n    Transformed data:\\n    Z ≈ [-1.414, -0.707, 0, 0.707, 1.414]\\n\\nStep 4: Verify results\\n    Mean of Z ≈ 0\\n    Std of Z = 1\\n\\n-----------------------------------------------------\\nSummary:\\n    StandardScaler transforms each feature so that\\n    it has mean = 0 and std = 1. This ensures all\\n    features are on the same scale.\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "StandardScaler Example (Step by Step)\n",
    "\n",
    "We want to standardize the data:\n",
    "    X = [10, 20, 30, 40, 50]\n",
    "\n",
    "Formula:\n",
    "    z_i = (x_i - μ) / σ\n",
    "    where μ = mean, σ = standard deviation\n",
    "\n",
    "-----------------------------------------------------\n",
    "Step 1: Compute mean (μ)\n",
    "    μ = (10 + 20 + 30 + 40 + 50) / 5 = 30\n",
    "\n",
    "Step 2: Compute variance and std (σ)\n",
    "    (10-30)² = 400\n",
    "    (20-30)² = 100\n",
    "    (30-30)² = 0\n",
    "    (40-30)² = 100\n",
    "    (50-30)² = 400\n",
    "    Sum = 1000\n",
    "\n",
    "    Variance = 1000 / 5 = 200\n",
    "    σ = √200 ≈ 14.142\n",
    "\n",
    "Step 3: Transform values (z = (x - μ) / σ)\n",
    "    For 10 → (10-30)/14.142 ≈ -1.414\n",
    "    For 20 → (20-30)/14.142 ≈ -0.707\n",
    "    For 30 → (30-30)/14.142 = 0\n",
    "    For 40 → (40-30)/14.142 ≈ 0.707\n",
    "    For 50 → (50-30)/14.142 ≈ 1.414\n",
    "\n",
    "    Transformed data:\n",
    "    Z ≈ [-1.414, -0.707, 0, 0.707, 1.414]\n",
    "\n",
    "Step 4: Verify results\n",
    "    Mean of Z ≈ 0\n",
    "    Std of Z = 1\n",
    "\n",
    "-----------------------------------------------------\n",
    "Summary:\n",
    "    StandardScaler transforms each feature so that\n",
    "    it has mean = 0 and std = 1. This ensures all\n",
    "    features are on the same scale.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b94f8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge's Mean Squared Error:  0.5209389458537057\n",
      "Ridge's R2 Score:  0.6074101939965981\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Initialize StandardScaler\n",
    "# StandardScaler will standardize data → mean = 0, std = 1\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Step 2: Fit the scaler on training data and transform it\n",
    "# - fit(): calculates mean and std from training data\n",
    "# - transform(): applies scaling using that mean and std\n",
    "# - fit_transform(): does both together\n",
    "x_train_scaled = scaler.fit_transform(x_train)\n",
    "\n",
    "# Step 3: Transform test data using training mean & std\n",
    "# NOTE: We only use transform here (not fit), because:\n",
    "#       - Test data must use same scaling as training\n",
    "#       - If we call fit again, it will leak test info (data leakage)\n",
    "x_test_scaled = scaler.transform(x_test)\n",
    "\n",
    "# Step 4: Initialize Ridge Regression with alpha=1.0 (penalty strength)\n",
    "ridge = Ridge(alpha=1.0)\n",
    "\n",
    "# Step 5: Train Ridge model on scaled training data\n",
    "ridge.fit(x_train_scaled, y_train)\n",
    "\n",
    "# Step 6: Predict target values on scaled test data\n",
    "y_pred_ridge = ridge.predict(x_test_scaled)\n",
    "\n",
    "# Step 7: Mean Squared Errir\n",
    "print(\"Ridge's Mean Squared Error: \", mean_squared_error(y_test, y_pred_ridge))\n",
    "\n",
    "# Step 7: Evaluate model performance using R² Score\n",
    "# R² measures how well predicted values match actual test values (1 = perfect)\n",
    "print(\"Ridge's R2 Score: \", r2_score(y_test, y_pred_ridge))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
